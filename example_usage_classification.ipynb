{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import shap\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "from typing import Callable, Optional, List, Dict, Tuple\n",
    "\n",
    "class Kraken:\n",
    "    \"\"\"\n",
    "    Based on the original idea of Mr. Patekha and proudly implemented in the author's vision\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        estimator: BaseEstimator, \n",
    "        cv: BaseCrossValidator, \n",
    "        metric: Callable, \n",
    "        meta_info_name: str):\n",
    "        \"\"\"\n",
    "        Initialize Kraken class with given estimator, cross-validator and metric.\n",
    "        \n",
    "        Args:\n",
    "            estimator (BaseEstimator): Estimator object.\n",
    "            cv (BaseCrossValidator): Cross-validator object.\n",
    "            metric (Callable): Metric function to evaluate model.\n",
    "            meta_info_name (str): name for meta_info file\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.cv = cv\n",
    "        self.metric = metric\n",
    "        self.meta_info_name = meta_info_name\n",
    "        \n",
    "        # temporary data\n",
    "        self.dict_fold_importances = None\n",
    "        self.fe_dict = None\n",
    "        self.rank_dict = None\n",
    "\n",
    "    def get_rank_dict(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        list_of_vars: List[str], \n",
    "        group_dt: Optional[np.ndarray] = None):\n",
    "        \"\"\"\n",
    "        Compute SHAP values and create a dictionary with ranked features by their absolute SHAP value.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "            y (np.ndarray): Target vector.\n",
    "            list_of_vars (List[str]): List of feature names.\n",
    "            group_dt (Optional[np.ndarray]): Group labels for the samples.\n",
    "        \n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        self.dict_fold_importances = {'Feature': list_of_vars, 'abs_shap': np.zeros(len(list_of_vars))}\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X, y, groups=group_dt), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            self.estimator.fit(X_train[list_of_vars], y_train)\n",
    "            explainer = shap.Explainer(self.estimator, X_train[list_of_vars])\n",
    "            shap_values = explainer(X_test[list_of_vars])\n",
    "            self.dict_fold_importances['abs_shap'] += np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "        self.fe_dict = {key: value for key, value in zip(self.dict_fold_importances['Feature'], self.dict_fold_importances['abs_shap'])}\n",
    "        self.rank_dict = {key: rank for rank, key in enumerate(sorted(self.fe_dict, key=self.fe_dict.get, reverse=True), 1)}\n",
    "\n",
    "    def get_cross_val_score(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        var: str, \n",
    "        old_scores: np.ndarray, \n",
    "        selected_vars: Optional[List[str]] = None, \n",
    "        group_dt: Optional[np.ndarray] = None, \n",
    "        round_num: int = 3) -> Tuple[np.ndarray, int, float]:\n",
    "        \"\"\"\n",
    "        Compute cross-validation scores for a given variable.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "            y (np.ndarray): Target vector.\n",
    "            var (str): Feature to evaluate.\n",
    "            old_scores (np.ndarray): Old cross-validation scores.\n",
    "            selected_vars (Optional[List[str]], optional): List of already selected features. Defaults to None.\n",
    "            group_dt (Optional[np.ndarray], optional): Group labels for the samples. Defaults to None.\n",
    "            round_num (int, optional): Number of decimal places for the scores. Defaults to 3.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, int, float]: Cross-validation scores, sum of the score differences between current and old scores and the mean cross-validation score.\n",
    "        \"\"\"\n",
    "        if selected_vars is None:\n",
    "            selected_vars = []\n",
    "        selected_vars.append(var)\n",
    "        list_scores = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X, y, groups=group_dt), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            self.estimator.fit(X_train[selected_vars], y_train)\n",
    "            preds = self.estimator.predict_proba(X_test[selected_vars])[:, 1]\n",
    "            error = round(self.metric(y_test, preds), round_num)\n",
    "            list_scores.append(error)\n",
    "        fold_scores = np.array(list_scores)\n",
    "        summa = sum(fold_scores - old_scores < 0) * 1 + sum(fold_scores - old_scores > 0) * -1\n",
    "        mean_cv_score = round(np.mean(fold_scores), round_num)\n",
    "        return fold_scores, summa, mean_cv_score\n",
    "\n",
    "    def get_vars(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        early_stopping_rounds: int = 30, \n",
    "        summa_approve: int = 1, \n",
    "        best_mean_cv: int = 10**10, \n",
    "        vars_in_model: Optional[List] = list(), \n",
    "        group_dt: Optional[np.ndarray] = None, \n",
    "        round_num: int = 3, \n",
    "        old_scores: Optional[np.ndarray] = None) -> List[str]:\n",
    "        \"\"\"\n",
    "        Select variables based on their SHAP values and cross-validation scores.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "            y (np.ndarray): Target vector.\n",
    "            early_stopping_rounds (int, optional): Number of iterations without improvement to stop the selection.\n",
    "                Defaults to 30.\n",
    "            summa_approve (int, optional): Threshold for the sum of score differences to approve the variable. Defaults to 1.\n",
    "            best_mean_cv (int, optional): Threshold for the mean cross-validation score to approve the variable. Defaults to 10**10.\n",
    "            vars_in_model (List[str], optional): List of initial variables. Defaults to [].\n",
    "            group_dt (Optional[np.ndarray], optional): Group labels for the samples. Defaults to None.\n",
    "            round_num (int, optional): Number of decimal places for the scores. Defaults to 3.\n",
    "        \"\"\"\n",
    "        self.round_num = round_num\n",
    "        if old_scores is None:\n",
    "            old_scores = np.array([0.5 for _ in range(self.cv.get_n_splits())])\n",
    "        iteration_step = 0\n",
    "        the_list_from_which_we_take_vars = [i for i in list(self.rank_dict.keys()) if i not in vars_in_model]\n",
    "        feature_was_added = True\n",
    "\n",
    "        while feature_was_added:\n",
    "            iteration_step = 0\n",
    "            var_for_add = ''\n",
    "            if iteration_step > 0:\n",
    "                print('начинаем след этап', best_mean_cv)\n",
    "            else:\n",
    "                print('запуск первого шага')\n",
    "            best_positive_groups = summa_approve\n",
    "            for var in the_list_from_which_we_take_vars:\n",
    "                iteration_step += 1\n",
    "                if iteration_step > early_stopping_rounds:\n",
    "                    print(f'early_stopping_rounds {early_stopping_rounds}')\n",
    "                    break\n",
    "                fold_scores, summa, mean_cv_score = self.get_cross_val_score(X=X, y=y, var=var, old_scores=old_scores, selected_vars=vars_in_model.copy(), group_dt=group_dt, round_num=self.round_num)\n",
    "                if (summa > best_positive_groups) or (summa == best_positive_groups and mean_cv_score < best_mean_cv):\n",
    "                    best_positive_groups = summa\n",
    "                    best_mean_cv = mean_cv_score\n",
    "                    old_scores = fold_scores\n",
    "                    var_for_add = var\n",
    "                    iteration_step = 0\n",
    "                    print(f'new var_for_add ! {var_for_add}')\n",
    "\n",
    "            if var_for_add != '':\n",
    "                vars_in_model.append(var_for_add)\n",
    "                the_list_from_which_we_take_vars.remove(var_for_add)\n",
    "                print('едем дальше')\n",
    "                print('в итоге получили список', vars_in_model)\n",
    "                list_meta = ['vars_list'] + [best_positive_groups] + [best_mean_cv] + old_scores.tolist()\n",
    "                df_meta = pd.DataFrame(list_meta).T\n",
    "                df_meta.columns = ['vars', 'summa', 'mean_cv_scores'] + ['cv' + str(i) for i in range(1, self.cv.get_n_splits() + 1)]\n",
    "                df_meta.at[0, 'vars'] = vars_in_model.copy()\n",
    "                try:\n",
    "                    df_meta_info = pd.concat([df_meta_info, df_meta])\n",
    "                except:\n",
    "                    df_meta_info = df_meta.copy()\n",
    "                df_meta_info.to_csv(f'df_meta_info_{self.meta_info_name}.csv')\n",
    "                continue\n",
    "            else:\n",
    "                feature_was_added = False\n",
    "\n",
    "        print('мы сошлись')\n",
    "        print(vars_in_model)\n",
    "        print(best_mean_cv)\n",
    "        return vars_in_model\n",
    "    \n",
    "    def reset_temp_data(self):\n",
    "        \"\"\"\n",
    "        Reset temporary data stored in the class attributes.\n",
    "        \"\"\"\n",
    "        self.dict_fold_importances = None\n",
    "        self.fe_dict = None\n",
    "        self.rank_dict = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Установка случайного зерна для воспроизводимости\n",
    "np.random.seed(42)\n",
    "\n",
    "# Генерация данных\n",
    "n_samples = 100\n",
    "feature1 = np.random.rand(n_samples)\n",
    "feature2 = np.random.rand(n_samples)\n",
    "feature3 = np.random.rand(n_samples)\n",
    "feature4 = np.random.rand(n_samples)  # Незначимый признак\n",
    "feature5 = np.random.rand(n_samples)  # Незначимый признак\n",
    "noise = np.random.normal(0, 0.1, n_samples)  # Небольшой шум\n",
    "\n",
    "# Вычисление целевого класса\n",
    "linear_combination = 0.3 * feature1 + 0.5 * feature2 + 0.2 * feature3 + noise\n",
    "target = (linear_combination > 0.5).astype(int)\n",
    "\n",
    "# Создание DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': feature1,\n",
    "    'Feature2': feature2,\n",
    "    'Feature3': feature3,\n",
    "    'Feature4': feature4,\n",
    "    'Feature5': feature5,\n",
    "    'Target': target\n",
    "})\n",
    "\n",
    "# Определение признаков и целевой переменной\n",
    "X = data.drop(columns='Target')\n",
    "y = data['Target']\n",
    "\n",
    "# Определение модели, кросс-валидатора и метрики\n",
    "estimator = RandomForestClassifier(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metric = roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|===================| 1964/2000 [00:30<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap_values.values.shape: (1000, 5, 2)\n",
      "shap_values_class1.shape: (1000, 5), len(list_of_vars): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|=================== | 1939/2000 [00:27<00:00]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap_values.values.shape: (1000, 5, 2)\n",
      "shap_values_class1.shape: (1000, 5), len(list_of_vars): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|=================== | 1935/2000 [00:26<00:00]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap_values.values.shape: (1000, 5, 2)\n",
      "shap_values_class1.shape: (1000, 5), len(list_of_vars): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|=================== | 1938/2000 [00:26<00:00]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap_values.values.shape: (1000, 5, 2)\n",
      "shap_values_class1.shape: (1000, 5), len(list_of_vars): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 1978/2000 [00:27<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap_values.values.shape: (1000, 5, 2)\n",
      "shap_values_class1.shape: (1000, 5), len(list_of_vars): 5\n",
      "запуск первого шага\n",
      "new var_for_add ! Feature5\n",
      "едем дальше\n",
      "в итоге получили список ['Feature5']\n",
      "запуск первого шага\n",
      "new var_for_add ! Feature4\n",
      "едем дальше\n",
      "в итоге получили список ['Feature5', 'Feature4']\n",
      "запуск первого шага\n",
      "мы сошлись\n",
      "['Feature5', 'Feature4']\n",
      "0.48\n",
      "Выбранные переменные: ['Feature5', 'Feature4']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import shap\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "from typing import Callable, Optional, List, Dict, Tuple\n",
    "\n",
    "class Kraken:\n",
    "    \"\"\"\n",
    "    Based on the original idea of Mr. Patekha and proudly implemented in the author's vision\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        estimator: BaseEstimator, \n",
    "        cv: BaseCrossValidator, \n",
    "        metric: Callable, \n",
    "        meta_info_name: str):\n",
    "        \"\"\"\n",
    "        Initialize Kraken class with given estimator, cross-validator and metric.\n",
    "        \n",
    "        Args:\n",
    "            estimator (BaseEstimator): Estimator object.\n",
    "            cv (BaseCrossValidator): Cross-validator object.\n",
    "            metric (Callable): Metric function to evaluate model.\n",
    "            meta_info_name (str): name for meta_info file\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.cv = cv\n",
    "        self.metric = metric\n",
    "        self.meta_info_name = meta_info_name\n",
    "        \n",
    "        # temporary data\n",
    "        self.dict_fold_importances = None\n",
    "        self.fe_dict = None\n",
    "        self.rank_dict = None\n",
    "\n",
    "    def get_rank_dict(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        list_of_vars: List[str], \n",
    "        group_dt: Optional[np.ndarray] = None):\n",
    "        \"\"\"\n",
    "        Compute SHAP values and create a dictionary with ranked features by their absolute SHAP value.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "            y (np.ndarray): Target vector.\n",
    "            list_of_vars (List[str]): List of feature names.\n",
    "            group_dt (Optional[np.ndarray]): Group labels for the samples.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        self.dict_fold_importances = {'Feature': list_of_vars, 'abs_shap': np.zeros(len(list_of_vars))}\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X, y, groups=group_dt), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            self.estimator.fit(X_train[list_of_vars], y_train)\n",
    "            explainer = shap.Explainer(self.estimator, X_train[list_of_vars])\n",
    "            shap_values = explainer(X_test[list_of_vars])\n",
    "\n",
    "            # Проверяем форму shap_values.values\n",
    "            print(f\"shap_values.values.shape: {shap_values.values.shape}\")  # Добавлено для отладки\n",
    "            if len(shap_values.values.shape) == 3:\n",
    "                shap_values_class1 = shap_values.values[:, :, 1]  # Выбираем класс 1\n",
    "            else:\n",
    "                shap_values_class1 = shap_values.values\n",
    "\n",
    "            # Убедимся, что размеры совпадают\n",
    "            print(f\"shap_values_class1.shape: {shap_values_class1.shape}, len(list_of_vars): {len(list_of_vars)}\")  # Добавлено для отладки\n",
    "            if shap_values_class1.shape[1] != len(list_of_vars):\n",
    "                print(f\"shap_values_class1.shape: {shap_values_class1.shape}, len(list_of_vars): {len(list_of_vars)}\")\n",
    "                raise ValueError(\"Shape of SHAP values does not match the number of features.\")\n",
    "\n",
    "            self.dict_fold_importances['abs_shap'] += np.abs(shap_values_class1).mean(axis=0)\n",
    "\n",
    "        self.fe_dict = {key: value for key, value in zip(self.dict_fold_importances['Feature'], self.dict_fold_importances['abs_shap'])}\n",
    "        self.rank_dict = {key: rank for rank, key in enumerate(sorted(self.fe_dict, key=self.fe_dict.get, reverse=True), 1)}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_cross_val_score(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        var: str, \n",
    "        old_scores: np.ndarray, \n",
    "        selected_vars: Optional[List[str]] = None, \n",
    "        group_dt: Optional[np.ndarray] = None, \n",
    "        round_num: int = 3) -> Tuple[np.ndarray, int, float]:\n",
    "        \"\"\"\n",
    "        Compute cross-validation scores for a given variable.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "            y (np.ndarray): Target vector.\n",
    "            var (str): Feature to evaluate.\n",
    "            old_scores (np.ndarray): Old cross-validation scores.\n",
    "            selected_vars (Optional[List[str]], optional): List of already selected features. Defaults to None.\n",
    "            group_dt (Optional[np.ndarray], optional): Group labels for the samples. Defaults to None.\n",
    "            round_num (int, optional): Number of decimal places for the scores. Defaults to 3.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, int, float]: Cross-validation scores, sum of the score differences between current and old scores and the mean cross-validation score.\n",
    "        \"\"\"\n",
    "        if selected_vars is None:\n",
    "            selected_vars = []\n",
    "        selected_vars.append(var)\n",
    "        list_scores = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X, y, groups=group_dt), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            self.estimator.fit(X_train[selected_vars], y_train)\n",
    "            preds = self.estimator.predict_proba(X_test[selected_vars])[:, 1]\n",
    "            error = round(self.metric(y_test, preds), round_num)\n",
    "            list_scores.append(error)\n",
    "        fold_scores = np.array(list_scores)\n",
    "        summa = sum(fold_scores - old_scores < 0) * 1 + sum(fold_scores - old_scores > 0) * -1\n",
    "        mean_cv_score = round(np.mean(fold_scores), round_num)\n",
    "        return fold_scores, summa, mean_cv_score\n",
    "\n",
    "    def get_vars(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        early_stopping_rounds: int = 30, \n",
    "        summa_approve: int = 1, \n",
    "        best_mean_cv: int = 10**10, \n",
    "        vars_in_model: Optional[List] = list(), \n",
    "        group_dt: Optional[np.ndarray] = None, \n",
    "        round_num: int = 3, \n",
    "        old_scores: Optional[np.ndarray] = None) -> List[str]:\n",
    "        \"\"\"\n",
    "        Select variables based on their SHAP values and cross-validation scores.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "            y (np.ndarray): Target vector.\n",
    "            early_stopping_rounds (int, optional): Number of iterations without improvement to stop the selection.\n",
    "                Defaults to 30.\n",
    "            summa_approve (int, optional): Threshold for the sum of score differences to approve the variable. Defaults to 1.\n",
    "            best_mean_cv (int, optional): Threshold for the mean cross-validation score to approve the variable. Defaults to 10**10.\n",
    "            vars_in_model (List[str], optional): List of initial variables. Defaults to [].\n",
    "            group_dt (Optional[np.ndarray], optional): Group labels for the samples. Defaults to None.\n",
    "            round_num (int, optional): Number of decimal places for the scores. Defaults to 3.\n",
    "        \"\"\"\n",
    "        self.round_num = round_num\n",
    "        if old_scores is None:\n",
    "            old_scores = np.array([0.5 for _ in range(self.cv.get_n_splits())])\n",
    "        iteration_step = 0\n",
    "        the_list_from_which_we_take_vars = [i for i in list(self.rank_dict.keys()) if i not in vars_in_model]\n",
    "        feature_was_added = True\n",
    "\n",
    "        while feature_was_added:\n",
    "            iteration_step = 0\n",
    "            var_for_add = ''\n",
    "            if iteration_step > 0:\n",
    "                print('начинаем след этап', best_mean_cv)\n",
    "            else:\n",
    "                print('запуск первого шага')\n",
    "            best_positive_groups = summa_approve\n",
    "            for var in the_list_from_which_we_take_vars:\n",
    "                iteration_step += 1\n",
    "                if iteration_step > early_stopping_rounds:\n",
    "                    print(f'early_stopping_rounds {early_stopping_rounds}')\n",
    "                    break\n",
    "                fold_scores, summa, mean_cv_score = self.get_cross_val_score(X=X, y=y, var=var, old_scores=old_scores, selected_vars=vars_in_model.copy(), group_dt=group_dt, round_num=self.round_num)\n",
    "                if (summa > best_positive_groups) or (summa == best_positive_groups and mean_cv_score < best_mean_cv):\n",
    "                    best_positive_groups = summa\n",
    "                    best_mean_cv = mean_cv_score\n",
    "                    old_scores = fold_scores\n",
    "                    var_for_add = var\n",
    "                    iteration_step = 0\n",
    "                    print(f'new var_for_add ! {var_for_add}')\n",
    "\n",
    "            if var_for_add != '':\n",
    "                vars_in_model.append(var_for_add)\n",
    "                the_list_from_which_we_take_vars.remove(var_for_add)\n",
    "                print('едем дальше')\n",
    "                print('в итоге получили список', vars_in_model)\n",
    "                list_meta = ['vars_list'] + [best_positive_groups] + [best_mean_cv] + old_scores.tolist()\n",
    "                df_meta = pd.DataFrame(list_meta).T\n",
    "                df_meta.columns = ['vars', 'summa', 'mean_cv_scores'] + ['cv' + str(i) for i in range(1, self.cv.get_n_splits() + 1)]\n",
    "                df_meta.at[0, 'vars'] = vars_in_model.copy()\n",
    "                try:\n",
    "                    df_meta_info = pd.concat([df_meta_info, df_meta])\n",
    "                except:\n",
    "                    df_meta_info = df_meta.copy()\n",
    "                df_meta_info.to_csv(f'df_meta_info_{self.meta_info_name}.csv')\n",
    "                continue\n",
    "            else:\n",
    "                feature_was_added = False\n",
    "\n",
    "        print('мы сошлись')\n",
    "        print(vars_in_model)\n",
    "        print(best_mean_cv)\n",
    "        return vars_in_model\n",
    "    \n",
    "    def reset_temp_data(self):\n",
    "        \"\"\"\n",
    "        Reset temporary data stored in the class attributes.\n",
    "        \"\"\"\n",
    "        self.dict_fold_importances = None\n",
    "        self.fe_dict = None\n",
    "        self.rank_dict = None\n",
    "\n",
    "# Установка случайного зерна для воспроизводимости\n",
    "np.random.seed(42)\n",
    "\n",
    "# Генерация данных\n",
    "n_samples = 5000\n",
    "feature1 = np.random.rand(n_samples)\n",
    "feature2 = np.random.rand(n_samples)\n",
    "feature3 = np.random.rand(n_samples)\n",
    "feature4 = np.random.rand(n_samples)  # Незначимый признак\n",
    "feature5 = np.random.rand(n_samples)  # Незначимый признак\n",
    "noise = np.random.normal(0, 0.1, n_samples)  # Небольшой шум\n",
    "\n",
    "# Вычисление целевого класса\n",
    "linear_combination = 0.3 * feature1 + 0.5 * feature2 + 0.2 * feature3 + noise\n",
    "target = (linear_combination > 0.5).astype(int)\n",
    "\n",
    "# Создание DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': feature1,\n",
    "    'Feature2': feature2,\n",
    "    'Feature3': feature3,\n",
    "    'Feature4': feature4,\n",
    "    'Feature5': feature5,\n",
    "    'Target': target\n",
    "})\n",
    "\n",
    "# Определение признаков и целевой переменной\n",
    "X = data.drop(columns='Target')\n",
    "y = data['Target']\n",
    "\n",
    "# Определение модели, кросс-валидатора и метрики\n",
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier(max_depth=3, verbosity = -1)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metric = roc_auc_score\n",
    "\n",
    "# Создание экземпляра класса Kraken\n",
    "kraken = Kraken(estimator=estimator, cv=cv, metric=metric, meta_info_name=\"meta_info\")\n",
    "\n",
    "# Получение ранжированного словаря признаков\n",
    "kraken.get_rank_dict(X, y, list(X.columns))\n",
    "\n",
    "# Получение выбранных переменных\n",
    "selected_vars = kraken.get_vars(X, y)\n",
    "\n",
    "print(\"Выбранные переменные:\", selected_vars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfa_bank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
