{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import shap\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "from typing import Callable, Optional, List, Dict, Tuple\n",
    "\n",
    "class Kraken:\n",
    "    \"\"\"\n",
    "    Based on the original idea of Mr. Patekha and proudly implemented in the author's vision\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        estimator: BaseEstimator, \n",
    "        cv: BaseCrossValidator, \n",
    "        metric: Callable, \n",
    "        meta_info_name: str):\n",
    "        \"\"\"\n",
    "        Initialize Kraken class with given estimator, cross-validator and metric.\n",
    "        \n",
    "        Args:\n",
    "            estimator (BaseEstimator): Estimator object.\n",
    "            cv (BaseCrossValidator): Cross-validator object.\n",
    "            metric (Callable): Metric function to evaluate model.\n",
    "            meta_info_name (str): name for meta_info file\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.cv = cv\n",
    "        self.metric = metric\n",
    "        self.meta_info_name = meta_info_name\n",
    "        \n",
    "        # temporary data\n",
    "        self.dict_fold_importances = None\n",
    "        self.fe_dict = None\n",
    "        self.rank_dict = None\n",
    "\n",
    "    def get_rank_dict(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        list_of_vars: List[str], \n",
    "        group_dt: Optional[np.ndarray] = None):\n",
    "        \"\"\"\n",
    "        Compute SHAP values and create a dictionary with ranked features by their absolute SHAP value.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "            y (np.ndarray): Target vector.\n",
    "            list_of_vars (List[str]): List of feature names.\n",
    "            group_dt (Optional[np.ndarray]): Group labels for the samples.\n",
    "        \n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        self.dict_fold_importances = {'Feature': list_of_vars, 'abs_shap': np.zeros(len(list_of_vars))}\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X, y, groups=group_dt), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            self.estimator.fit(X_train[list_of_vars], y_train)\n",
    "            explainer = shap.Explainer(self.estimator, X_train[list_of_vars])\n",
    "            shap_values = explainer(X_test[list_of_vars])\n",
    "            self.dict_fold_importances['abs_shap'] += np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "        self.fe_dict = {key: value for key, value in zip(self.dict_fold_importances['Feature'], self.dict_fold_importances['abs_shap'])}\n",
    "        self.rank_dict = {key: rank for rank, key in enumerate(sorted(self.fe_dict, key=self.fe_dict.get, reverse=True), 1)}\n",
    "\n",
    "    def get_cross_val_score(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        var: str, \n",
    "        old_scores: np.ndarray, \n",
    "        selected_vars: Optional[List[str]] = None, \n",
    "        group_dt: Optional[np.ndarray] = None, \n",
    "        round_num: int = 3) -> Tuple[np.ndarray, int, float]:\n",
    "        \"\"\"\n",
    "        Compute cross-validation scores for a given variable.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "            y (np.ndarray): Target vector.\n",
    "            var (str): Feature to evaluate.\n",
    "            old_scores (np.ndarray): Old cross-validation scores.\n",
    "            selected_vars (Optional[List[str]], optional): List of already selected features. Defaults to None.\n",
    "            group_dt (Optional[np.ndarray], optional): Group labels for the samples. Defaults to None.\n",
    "            round_num (int, optional): Number of decimal places for the scores. Defaults to 3.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, int, float]: Cross-validation scores, sum of the score differences between current and old scores and the mean cross-validation score.\n",
    "        \"\"\"\n",
    "        if selected_vars is None:\n",
    "            selected_vars = []\n",
    "        selected_vars.append(var)\n",
    "        list_scores = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X, y, groups=group_dt), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            self.estimator.fit(X_train[selected_vars], y_train)\n",
    "            preds = self.estimator.predict_proba(X_test[selected_vars])[:, 1]\n",
    "            error = round(self.metric(y_test, preds), round_num)\n",
    "            list_scores.append(error)\n",
    "        fold_scores = np.array(list_scores)\n",
    "        summa = sum(fold_scores - old_scores < 0) * 1 + sum(fold_scores - old_scores > 0) * -1\n",
    "        mean_cv_score = round(np.mean(fold_scores), round_num)\n",
    "        return fold_scores, summa, mean_cv_score\n",
    "\n",
    "    def get_vars(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        early_stopping_rounds: int = 30, \n",
    "        summa_approve: int = 1, \n",
    "        best_mean_cv: int = 10**10, \n",
    "        vars_in_model: Optional[List] = list(), \n",
    "        group_dt: Optional[np.ndarray] = None, \n",
    "        round_num: int = 3, \n",
    "        old_scores: Optional[np.ndarray] = None) -> List[str]:\n",
    "        \"\"\"\n",
    "        Select variables based on their SHAP values and cross-validation scores.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "            y (np.ndarray): Target vector.\n",
    "            early_stopping_rounds (int, optional): Number of iterations without improvement to stop the selection.\n",
    "                Defaults to 30.\n",
    "            summa_approve (int, optional): Threshold for the sum of score differences to approve the variable. Defaults to 1.\n",
    "            best_mean_cv (int, optional): Threshold for the mean cross-validation score to approve the variable. Defaults to 10**10.\n",
    "            vars_in_model (List[str], optional): List of initial variables. Defaults to [].\n",
    "            group_dt (Optional[np.ndarray], optional): Group labels for the samples. Defaults to None.\n",
    "            round_num (int, optional): Number of decimal places for the scores. Defaults to 3.\n",
    "        \"\"\"\n",
    "        self.round_num = round_num\n",
    "        if old_scores is None:\n",
    "            old_scores = np.array([0.5 for _ in range(self.cv.get_n_splits())])\n",
    "        iteration_step = 0\n",
    "        the_list_from_which_we_take_vars = [i for i in list(self.rank_dict.keys()) if i not in vars_in_model]\n",
    "        feature_was_added = True\n",
    "\n",
    "        while feature_was_added:\n",
    "            iteration_step = 0\n",
    "            var_for_add = ''\n",
    "            if iteration_step > 0:\n",
    "                print('начинаем след этап', best_mean_cv)\n",
    "            else:\n",
    "                print('запуск первого шага')\n",
    "            best_positive_groups = summa_approve\n",
    "            for var in the_list_from_which_we_take_vars:\n",
    "                iteration_step += 1\n",
    "                if iteration_step > early_stopping_rounds:\n",
    "                    print(f'early_stopping_rounds {early_stopping_rounds}')\n",
    "                    break\n",
    "                fold_scores, summa, mean_cv_score = self.get_cross_val_score(X=X, y=y, var=var, old_scores=old_scores, selected_vars=vars_in_model.copy(), group_dt=group_dt, round_num=self.round_num)\n",
    "                if (summa > best_positive_groups) or (summa == best_positive_groups and mean_cv_score < best_mean_cv):\n",
    "                    best_positive_groups = summa\n",
    "                    best_mean_cv = mean_cv_score\n",
    "                    old_scores = fold_scores\n",
    "                    var_for_add = var\n",
    "                    iteration_step = 0\n",
    "                    print(f'new var_for_add ! {var_for_add}')\n",
    "\n",
    "            if var_for_add != '':\n",
    "                vars_in_model.append(var_for_add)\n",
    "                the_list_from_which_we_take_vars.remove(var_for_add)\n",
    "                print('едем дальше')\n",
    "                print('в итоге получили список', vars_in_model)\n",
    "                list_meta = ['vars_list'] + [best_positive_groups] + [best_mean_cv] + old_scores.tolist()\n",
    "                df_meta = pd.DataFrame(list_meta).T\n",
    "                df_meta.columns = ['vars', 'summa', 'mean_cv_scores'] + ['cv' + str(i) for i in range(1, self.cv.get_n_splits() + 1)]\n",
    "                df_meta.at[0, 'vars'] = vars_in_model.copy()\n",
    "                try:\n",
    "                    df_meta_info = pd.concat([df_meta_info, df_meta])\n",
    "                except:\n",
    "                    df_meta_info = df_meta.copy()\n",
    "                df_meta_info.to_csv(f'df_meta_info_{self.meta_info_name}.csv')\n",
    "                continue\n",
    "            else:\n",
    "                feature_was_added = False\n",
    "\n",
    "        print('мы сошлись')\n",
    "        print(vars_in_model)\n",
    "        print(best_mean_cv)\n",
    "        return vars_in_model\n",
    "    \n",
    "    def reset_temp_data(self):\n",
    "        \"\"\"\n",
    "        Reset temporary data stored in the class attributes.\n",
    "        \"\"\"\n",
    "        self.dict_fold_importances = None\n",
    "        self.fe_dict = None\n",
    "        self.rank_dict = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Установка случайного зерна для воспроизводимости\n",
    "np.random.seed(42)\n",
    "\n",
    "# Генерация данных\n",
    "n_samples = 100\n",
    "feature1 = np.random.rand(n_samples)\n",
    "feature2 = np.random.rand(n_samples)\n",
    "feature3 = np.random.rand(n_samples)\n",
    "feature4 = np.random.rand(n_samples)  # Незначимый признак\n",
    "feature5 = np.random.rand(n_samples)  # Незначимый признак\n",
    "noise = np.random.normal(0, 0.1, n_samples)  # Небольшой шум\n",
    "\n",
    "# Вычисление целевого класса\n",
    "linear_combination = 0.3 * feature1 + 0.5 * feature2 + 0.2 * feature3 + noise\n",
    "target = (linear_combination > 0.5).astype(int)\n",
    "\n",
    "# Создание DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': feature1,\n",
    "    'Feature2': feature2,\n",
    "    'Feature3': feature3,\n",
    "    'Feature4': feature4,\n",
    "    'Feature5': feature5,\n",
    "    'Target': target\n",
    "})\n",
    "\n",
    "# Определение признаков и целевой переменной\n",
    "X = data.drop(columns='Target')\n",
    "y = data['Target']\n",
    "\n",
    "# Определение модели, кросс-валидатора и метрики\n",
    "estimator = RandomForestClassifier(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "def custom()\n",
    "metric = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import shap\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "from typing import Callable, Optional, List, Dict, Tuple\n",
    "\n",
    "class Kraken:\n",
    "    \"\"\"\n",
    "    Based on the original idea of Mr. Patekha and proudly implemented in the author's vision\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        estimator: BaseEstimator, \n",
    "        cv: BaseCrossValidator, \n",
    "        metric: Callable, \n",
    "        meta_info_name: str):\n",
    "        \"\"\"\n",
    "        Initialize Kraken class with given estimator, cross-validator and metric.\n",
    "        \n",
    "        Args:\n",
    "            estimator (BaseEstimator): Estimator object.\n",
    "            cv (BaseCrossValidator): Cross-validator object.\n",
    "            metric (Callable): Metric function to evaluate model.\n",
    "            meta_info_name (str): name for meta_info file\n",
    "        \"\"\"\n",
    "        self.estimator = estimator\n",
    "        self.cv = cv\n",
    "        self.metric = metric\n",
    "        self.meta_info_name = meta_info_name\n",
    "        \n",
    "        # temporary data\n",
    "        self.dict_fold_importances = None\n",
    "        self.fe_dict = None\n",
    "        self.rank_dict = None\n",
    "\n",
    "    def get_rank_dict(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        list_of_vars: List[str], \n",
    "        group_dt: Optional[np.ndarray] = None):\n",
    "        \"\"\"\n",
    "        Compute SHAP values and create a dictionary with ranked features by their absolute SHAP value.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "            y (np.ndarray): Target vector.\n",
    "            list_of_vars (List[str]): List of feature names.\n",
    "            group_dt (Optional[np.ndarray]): Group labels for the samples.\n",
    "\n",
    "        Returns:\n",
    "            None.\n",
    "        \"\"\"\n",
    "        self.dict_fold_importances = {'Feature': list_of_vars, 'abs_shap': np.zeros(len(list_of_vars))}\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X, y, groups=group_dt), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            self.estimator.fit(X_train[list_of_vars], y_train)\n",
    "            explainer = shap.Explainer(self.estimator, X_train[list_of_vars])\n",
    "            shap_values = explainer(X_test[list_of_vars])\n",
    "\n",
    "            # Проверяем форму shap_values.values\n",
    "            print(f\"shap_values.values.shape: {shap_values.values.shape}\")  # Добавлено для отладки\n",
    "            if len(shap_values.values.shape) == 3:\n",
    "                shap_values_class1 = shap_values.values[:, :, 1]  # Выбираем класс 1\n",
    "            else:\n",
    "                shap_values_class1 = shap_values.values\n",
    "\n",
    "            # Убедимся, что размеры совпадают\n",
    "            print(f\"shap_values_class1.shape: {shap_values_class1.shape}, len(list_of_vars): {len(list_of_vars)}\")  # Добавлено для отладки\n",
    "            if shap_values_class1.shape[1] != len(list_of_vars):\n",
    "                print(f\"shap_values_class1.shape: {shap_values_class1.shape}, len(list_of_vars): {len(list_of_vars)}\")\n",
    "                raise ValueError(\"Shape of SHAP values does not match the number of features.\")\n",
    "\n",
    "            self.dict_fold_importances['abs_shap'] += np.abs(shap_values_class1).mean(axis=0)\n",
    "\n",
    "        self.fe_dict = {key: value for key, value in zip(self.dict_fold_importances['Feature'], self.dict_fold_importances['abs_shap'])}\n",
    "        self.rank_dict = {key: rank for rank, key in enumerate(sorted(self.fe_dict, key=self.fe_dict.get, reverse=True), 1)}\n",
    "\n",
    "\n",
    "\n",
    "    def get_cross_val_score(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        var: str, \n",
    "        old_scores: np.ndarray, \n",
    "        selected_vars: Optional[List[str]] = None, \n",
    "        group_dt: Optional[np.ndarray] = None, \n",
    "        round_num: int = 3) -> Tuple[np.ndarray, int, float]:\n",
    "        \"\"\"\n",
    "        Compute cross-validation scores for a given variable.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "            y (np.ndarray): Target vector.\n",
    "            var (str): Feature to evaluate.\n",
    "            old_scores (np.ndarray): Old cross-validation scores.\n",
    "            selected_vars (Optional[List[str]], optional): List of already selected features. Defaults to None.\n",
    "            group_dt (Optional[np.ndarray], optional): Group labels for the samples. Defaults to None.\n",
    "            round_num (int, optional): Number of decimal places for the scores. Defaults to 3.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, int, float]: Cross-validation scores, sum of the score differences between current and old scores and the mean \n",
    "            cross-validation score.\n",
    "        \"\"\"\n",
    "        if selected_vars is None:\n",
    "            selected_vars = []\n",
    "        selected_vars.append(var)\n",
    "        list_scores = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X, y, groups=group_dt), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            self.estimator.fit(X_train[selected_vars], y_train)\n",
    "            preds = self.estimator.predict_proba(X_test[selected_vars])[:, 1]\n",
    "            error = round(self.metric(y_test, preds), round_num)\n",
    "            list_scores.append(error)\n",
    "        fold_scores = np.array(list_scores)\n",
    "        summa = sum(fold_scores - old_scores < 0) * 1 + sum(fold_scores - old_scores > 0) * -1\n",
    "        mean_cv_score = round(np.mean(fold_scores), round_num)\n",
    "        return fold_scores, summa, mean_cv_score\n",
    "\n",
    "    def get_vars(\n",
    "        self, \n",
    "        X: np.ndarray, \n",
    "        y: np.ndarray, \n",
    "        early_stopping_rounds: int = 30, \n",
    "        summa_approve: int = 1, \n",
    "        best_mean_cv: int = 100, \n",
    "        vars_in_model: Optional[List] = list(), \n",
    "        group_dt: Optional[np.ndarray] = None, \n",
    "        round_num: int = 3, \n",
    "        old_scores: Optional[np.ndarray] = None) -> List[str]:\n",
    "        \"\"\"\n",
    "        Select variables based on their SHAP values and cross-validation scores.\n",
    "        \n",
    "        Args:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "            y (np.ndarray): Target vector.\n",
    "            early_stopping_rounds (int, optional): Number of iterations without improvement to stop the selection.\n",
    "                Defaults to 30.\n",
    "            summa_approve (int, optional): Threshold for the sum of score differences to approve the variable. Defaults to 1.\n",
    "            best_mean_cv (int, optional): Threshold for the mean cross-validation score to approve the variable. Defaults to 10**10.\n",
    "            vars_in_model (List[str], optional): List of initial variables. Defaults to [].\n",
    "            group_dt (Optional[np.ndarray], optional): Group labels for the samples. Defaults to None.\n",
    "            round_num (int, optional): Number of decimal places for the scores. Defaults to 3.\n",
    "        \"\"\"\n",
    "        self.round_num = round_num\n",
    "        if old_scores is None:\n",
    "            old_scores = np.array([0.5 for _ in range(self.cv.get_n_splits())])\n",
    "        iteration_step = 0\n",
    "        the_list_from_which_we_take_vars = [i for i in list(self.rank_dict.keys()) if i not in vars_in_model]\n",
    "        feature_was_added = True\n",
    "\n",
    "        while feature_was_added:\n",
    "            iteration_step = 0\n",
    "            var_for_add = ''\n",
    "            if iteration_step > 0:\n",
    "                print('начинаем след этап', best_mean_cv)\n",
    "            else:\n",
    "                print('запуск первого шага')\n",
    "            best_positive_groups = summa_approve\n",
    "            for var in the_list_from_which_we_take_vars:\n",
    "                iteration_step += 1\n",
    "                if iteration_step > early_stopping_rounds:\n",
    "                    print(f'early_stopping_rounds {early_stopping_rounds}')\n",
    "                    break\n",
    "                fold_scores, summa, mean_cv_score = self.get_cross_val_score(X=X, y=y, var=var, old_scores=old_scores, selected_vars=vars_in_model.copy(), \n",
    "                                                                             group_dt=group_dt, round_num=self.round_num)\n",
    "                if (summa > best_positive_groups) or (summa == best_positive_groups and mean_cv_score < best_mean_cv):\n",
    "                    best_positive_groups = summa\n",
    "                    best_mean_cv = mean_cv_score\n",
    "                    old_scores = fold_scores\n",
    "                    var_for_add = var\n",
    "                    iteration_step = 0\n",
    "                    print(f'new var_for_add ! {var_for_add}')\n",
    "\n",
    "            if var_for_add != '':\n",
    "                vars_in_model.append(var_for_add)\n",
    "                the_list_from_which_we_take_vars.remove(var_for_add)\n",
    "                print('едем дальше')\n",
    "                print('в итоге получили список', vars_in_model)\n",
    "                list_meta = ['vars_list'] + [best_positive_groups] + [best_mean_cv] + old_scores.tolist()\n",
    "                df_meta = pd.DataFrame(list_meta).T\n",
    "                df_meta.columns = ['vars', 'summa', 'mean_cv_scores'] + ['cv' + str(i) for i in range(1, self.cv.get_n_splits() + 1)]\n",
    "                df_meta.at[0, 'vars'] = vars_in_model.copy()\n",
    "                try:\n",
    "                    df_meta_info = pd.concat([df_meta_info, df_meta])\n",
    "                except:\n",
    "                    df_meta_info = df_meta.copy()\n",
    "                df_meta_info.to_csv(f'df_meta_info_{self.meta_info_name}.csv')\n",
    "                continue\n",
    "            else:\n",
    "                feature_was_added = False\n",
    "\n",
    "        print('мы сошлись')\n",
    "        print(vars_in_model)\n",
    "        #print(best_mean_cv)\n",
    "        return vars_in_model\n",
    "    \n",
    "    def reset_temp_data(self):\n",
    "        \"\"\"\n",
    "        Reset temporary data stored in the class attributes.\n",
    "        \"\"\"\n",
    "        self.dict_fold_importances = None\n",
    "        self.fe_dict = None\n",
    "        self.rank_dict = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|=================== | 2602/2680 [00:31<00:00]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap_values.values.shape: (1340, 5, 2)\n",
      "shap_values_class1.shape: (1340, 5), len(list_of_vars): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 2647/2680 [00:30<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap_values.values.shape: (1340, 5, 2)\n",
      "shap_values_class1.shape: (1340, 5), len(list_of_vars): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|===================| 2629/2680 [00:30<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap_values.values.shape: (1340, 5, 2)\n",
      "shap_values_class1.shape: (1340, 5), len(list_of_vars): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 2644/2680 [00:30<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap_values.values.shape: (1340, 5, 2)\n",
      "shap_values_class1.shape: (1340, 5), len(list_of_vars): 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|===================| 2632/2680 [00:33<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap_values.values.shape: (1340, 5, 2)\n",
      "shap_values_class1.shape: (1340, 5), len(list_of_vars): 5\n",
      "запуск первого шага\n",
      "мы сошлись\n",
      "['Feature4', 'Feature5', 'Feature2', 'Feature1', 'Feature3']\n",
      "Выбранные переменные: ['Feature4', 'Feature5', 'Feature2', 'Feature1', 'Feature3']\n"
     ]
    }
   ],
   "source": [
    "# Установка случайного зерна для воспроизводимости\n",
    "np.random.seed(42)\n",
    "\n",
    "# Генерация данных\n",
    "n_samples = 10000\n",
    "feature1 = np.random.rand(n_samples)\n",
    "feature2 = np.random.rand(n_samples)\n",
    "feature3 = np.random.rand(n_samples)\n",
    "feature4 = np.random.rand(n_samples)  # Незначимый признак\n",
    "feature5 = np.random.rand(n_samples)  # Незначимый признак\n",
    "noise = np.random.normal(0, 0.1, n_samples)  # Небольшой шум\n",
    "\n",
    "# Вычисление целевого класса\n",
    "linear_combination = 0.33*feature1 + 0.5*feature2 + 0.17*feature3 + noise\n",
    "target = (linear_combination > 0.5).astype(int)\n",
    "\n",
    "# Создание DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': feature1,\n",
    "    'Feature2': feature2,\n",
    "    'Feature3': feature3,\n",
    "    'Feature4': feature4,\n",
    "    'Feature5': feature5,\n",
    "    'Target': target\n",
    "})\n",
    "\n",
    "# Определение признаков и целевой переменной\n",
    "X = data.drop(columns='Target')\n",
    "y = data['Target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Определение модели, кросс-валидатора и метрики\n",
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier(max_depth=3, verbosity = -1)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "def custom_metric(y_test, preds):\n",
    "    return 1 - roc_auc_score(y_test, preds)\n",
    "metric = custom_metric\n",
    "\n",
    "\n",
    "# Создание экземпляра класса Kraken\n",
    "kraken = Kraken(estimator=estimator, cv=cv, metric=metric, meta_info_name=\"meta_info\")\n",
    "\n",
    "# Получение ранжированного словаря признаков\n",
    "kraken.get_rank_dict(X_train, y_train, list(X.columns))\n",
    "\n",
    "# Получение выбранных переменных\n",
    "selected_vars = kraken.get_vars(X, y)\n",
    "\n",
    "print(\"Выбранные переменные:\", selected_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.936177</td>\n",
       "      <td>0.671368</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>0.884194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.110052</td>\n",
       "      <td>0.458941</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>0.895067</td>\n",
       "      <td>0.973941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>0.174109</td>\n",
       "      <td>0.246961</td>\n",
       "      <td>0.256952</td>\n",
       "      <td>0.776391</td>\n",
       "      <td>0.291659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>0.971533</td>\n",
       "      <td>0.983712</td>\n",
       "      <td>0.441274</td>\n",
       "      <td>0.947284</td>\n",
       "      <td>0.069708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.899249</td>\n",
       "      <td>0.921069</td>\n",
       "      <td>0.346760</td>\n",
       "      <td>0.288958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0.992484</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.056333</td>\n",
       "      <td>0.750811</td>\n",
       "      <td>0.612855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.176528</td>\n",
       "      <td>0.465337</td>\n",
       "      <td>0.592483</td>\n",
       "      <td>0.382824</td>\n",
       "      <td>0.997650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>0.723420</td>\n",
       "      <td>0.271955</td>\n",
       "      <td>0.282667</td>\n",
       "      <td>0.993502</td>\n",
       "      <td>0.668259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>0.800587</td>\n",
       "      <td>0.396313</td>\n",
       "      <td>0.160713</td>\n",
       "      <td>0.484039</td>\n",
       "      <td>0.323850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.775528</td>\n",
       "      <td>0.814671</td>\n",
       "      <td>0.071907</td>\n",
       "      <td>0.849035</td>\n",
       "      <td>0.334246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2010 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature1  Feature2  Feature3  Feature4  Feature5\n",
       "2761  0.007842  0.936177  0.671368  0.111800  0.884194\n",
       "123   0.110052  0.458941  0.999461  0.895067  0.973941\n",
       "1808  0.174109  0.246961  0.256952  0.776391  0.291659\n",
       "2286  0.971533  0.983712  0.441274  0.947284  0.069708\n",
       "2147  0.357798  0.899249  0.921069  0.346760  0.288958\n",
       "...        ...       ...       ...       ...       ...\n",
       "1638  0.992484  0.751825  0.056333  0.750811  0.612855\n",
       "1095  0.176528  0.465337  0.592483  0.382824  0.997650\n",
       "1130  0.723420  0.271955  0.282667  0.993502  0.668259\n",
       "1294  0.800587  0.396313  0.160713  0.484039  0.323850\n",
       "860   0.775528  0.814671  0.071907  0.849035  0.334246\n",
       "\n",
       "[2010 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alfa_bank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
