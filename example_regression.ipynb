{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression dataset shape: (36156, 10)\n",
      "[get_rank_dict] Starting combined baseline evaluation and SHAP calculation...\n",
      "Fold: 1/3 | Status: Done (0.19s)              | Fold Time:   0.19s | Total Time:    0.22s                              \n",
      "Fold: 2/3 | Status: Done (0.19s)              | Fold Time:   0.19s | Total Time:    0.41s                              \n",
      "Fold: 3/3 | Status: Done (0.19s)              | Fold Time:   0.19s | Total Time:    0.61s                              \n",
      "------------------------------\n",
      "[get_rank_dict] >> FINAL Baseline Performance (All Features)\n",
      "    Mean CV Score: 1.16\n",
      "    Fold Scores: [1.18 1.2  1.09]\n",
      "[get_rank_dict] Completed calculation. Total time: 0.67 seconds.\n",
      "Rank dict (regression) top-5: {'var_2': 1, 'var_5': 2, 'var_4': 3, 'var_3': 4, 'var_1': 5}\n",
      "[get_vars] Evaluating initial feature set (if any)...\n",
      "[get_vars] Starting feature selection procedure...\n",
      "[get_vars] Starting from scratch (will check top 10 features first).\n",
      "\n",
      "--- Starting Step: Selecting feature #1 (Checking top 9) ---\n",
      "    CV Before Step: Inf | Target Summa Threshold to Add: 1\n",
      "Step 1 | Checks since last best: 08/10 | Checking cand. [9/9]: var_9 | Best valid cand. (step): var_2 (Summa: 3, CV: 1.81))\n",
      "--- Step finished in 4.70 seconds ---\n",
      "[+] Feature Added: 'var_2'\n",
      "    New Best Mean CV: 1.81 (Achieved Summa: 3)\n",
      "    Selected Features (1): ['var_2']\n",
      "    Meta info saved to df_meta_info_example_regression.csv\n",
      "\n",
      "--- Starting Step: Selecting feature #2 (Checking 8) ---\n",
      "    CV Before Step: 1.81 | Target Summa Threshold to Add: 1\n",
      "Step 2 | Checks since last best: 04/10 | Checking cand. [8/8]: var_9 | Best valid cand. (step): var_1 (Summa: 3, CV: 1.58))\n",
      "--- Step finished in 4.02 seconds ---\n",
      "[+] Feature Added: 'var_1'\n",
      "    New Best Mean CV: 1.58 (Achieved Summa: 3)\n",
      "    Selected Features (2): ['var_2', 'var_1']\n",
      "    Meta info saved to df_meta_info_example_regression.csv\n",
      "\n",
      "--- Starting Step: Selecting feature #3 (Checking 7) ---\n",
      "    CV Before Step: 1.58 | Target Summa Threshold to Add: 1\n",
      "Step 3 | Checks since last best: 05/10 | Checking cand. [7/7]: var_9 | Best valid cand. (step): var_4 (Summa: 3, CV: 1.38))\n",
      "--- Step finished in 3.69 seconds ---\n",
      "[+] Feature Added: 'var_4'\n",
      "    New Best Mean CV: 1.38 (Achieved Summa: 3)\n",
      "    Selected Features (3): ['var_2', 'var_1', 'var_4']\n",
      "    Meta info saved to df_meta_info_example_regression.csv\n",
      "\n",
      "--- Starting Step: Selecting feature #4 (Checking 6) ---\n",
      "    CV Before Step: 1.38 | Target Summa Threshold to Add: 1\n",
      "Step 4 | Checks since last best: 04/10 | Checking cand. [6/6]: var_9 | Best valid cand. (step): var_3 (Summa: 3, CV: 1.22))\n",
      "--- Step finished in 3.06 seconds ---\n",
      "[+] Feature Added: 'var_3'\n",
      "    New Best Mean CV: 1.22 (Achieved Summa: 3)\n",
      "    Selected Features (4): ['var_2', 'var_1', 'var_4', 'var_3']\n",
      "    Meta info saved to df_meta_info_example_regression.csv\n",
      "\n",
      "--- Starting Step: Selecting feature #5 (Checking 5) ---\n",
      "    CV Before Step: 1.22 | Target Summa Threshold to Add: 1\n",
      "Step 5 | Checks since last best: 04/10 | Checking cand. [5/5]: var_9 | Best valid cand. (step): var_5 (Summa: 2, CV: 1.14))\n",
      "--- Step finished in 2.52 seconds ---\n",
      "[+] Feature Added: 'var_5'\n",
      "    New Best Mean CV: 1.14 (Achieved Summa: 2)\n",
      "    Selected Features (5): ['var_2', 'var_1', 'var_4', 'var_3', 'var_5']\n",
      "    Meta info saved to df_meta_info_example_regression.csv\n",
      "\n",
      "--- Starting Step: Selecting feature #6 (Checking 4) ---\n",
      "    CV Before Step: 1.14 | Target Summa Threshold to Add: 1\n",
      "Step 6 | Checks since last best: 03/10 | Checking cand. [4/4]: var_9 | Best valid cand. (step): None  (Summa: N/A, CV: N/A)\n",
      "--- Step finished in 2.01 seconds ---\n",
      "[-] No feature found that improves the score in this step. Stopping.\n",
      "------------------------------\n",
      "[get_vars] Final feature set:\n",
      "  Features (5): ['var_2', 'var_1', 'var_4', 'var_3', 'var_5']\n",
      "  Best Mean CV achieved: 1.14\n",
      "  Baseline Mean CV (All Features): 1.16\n",
      "[get_vars] Completed in 20.30 seconds.\n",
      "Selected vars (regression): ['var_2', 'var_1', 'var_4', 'var_3', 'var_5']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import classes\n",
    "from Tools import DateTimeSeriesSplit, Kraken\n",
    "\n",
    "# model and metric for regression\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "\n",
    "# ==============================================================\n",
    "# example 1: regression\n",
    "# ==============================================================\n",
    "\n",
    "# set random seed value\n",
    "seed_value = 23\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# creating dataset\n",
    "c = 12052\n",
    "X1 = pd.DataFrame()\n",
    "X1['var_1'] = np.random.rand(c)\n",
    "X1['var_2'] = np.random.rand(c)\n",
    "X1['var_3'] = np.random.rand(c)\n",
    "X1['var_4'] = np.random.rand(c)\n",
    "X1['var_5'] = np.random.rand(c)\n",
    "X1['var_6'] = np.random.rand(c)\n",
    "X1['var_7'] = np.random.rand(c)\n",
    "X1['var_8'] = np.random.rand(c)\n",
    "X1['var_9'] = np.random.rand(c)\n",
    "X1['date'] = pd.date_range(start='1990-01-01', end='2022-12-30', freq='D')\n",
    "\n",
    "# create simple dependency for first part of data\n",
    "y1 = X1['var_1'] + 3 * X1['var_2'] - np.power(X1['var_3'], 1.5)\n",
    "\n",
    "X2 = pd.DataFrame()\n",
    "X2['var_1'] = np.random.rand(c)\n",
    "X2['var_2'] = np.random.rand(c)\n",
    "X2['var_3'] = np.random.rand(c)\n",
    "X2['var_4'] = np.random.rand(c)\n",
    "X2['var_5'] = np.random.rand(c)\n",
    "X2['var_6'] = np.random.rand(c)\n",
    "X2['var_7'] = np.random.rand(c)\n",
    "X2['var_8'] = np.random.rand(c)\n",
    "X2['var_9'] = np.random.rand(c)\n",
    "X2['date'] = pd.date_range(start='1990-01-01', end='2022-12-30', freq='D')\n",
    "\n",
    "# add var_4 to dependency for second part\n",
    "y2 = X2['var_1'] + 3 * X2['var_2'] - np.power(X2['var_3'], 1.5) + 2 * X2['var_4']\n",
    "\n",
    "X3 = pd.DataFrame()\n",
    "X3['var_1'] = np.random.rand(c)\n",
    "X3['var_2'] = np.random.rand(c)\n",
    "X3['var_3'] = np.random.rand(c)\n",
    "X3['var_4'] = np.random.rand(c)\n",
    "X3['var_5'] = np.random.rand(c) \n",
    "X3['var_6'] = np.random.rand(c)\n",
    "X3['var_7'] = np.random.rand(c)\n",
    "X3['var_8'] = np.random.rand(c)\n",
    "X3['var_9'] = np.random.rand(c)\n",
    "X3['date'] = pd.date_range(start='1990-01-01', end='2022-12-30', freq='D')\n",
    "\n",
    "# add var_4 and var_5 to dependency for third part\n",
    "y3 = X3['var_1'] + 3 * X3['var_2'] - np.power(X3['var_3'], 1.5) + 2 * X3['var_4'] + 4 * X3['var_5']\n",
    "\n",
    "X = pd.concat([X1, X2, X3], axis=0)\n",
    "y = pd.concat([y1, y2, y3], axis=0)\n",
    "\n",
    "print(\"Regression dataset shape:\", X.shape)\n",
    "\n",
    "# creating cross validator\n",
    "cv_datetime = DateTimeSeriesSplit(window=3000, n_splits=3, test_size=300, margin=0)\n",
    "group_dt = X['date']\n",
    "\n",
    "# create model for selector\n",
    "model_reg = LGBMRegressor(max_depth=3, verbosity=-1)\n",
    "\n",
    "# create list of variables for model\n",
    "list_of_vars = list(X.columns)\n",
    "list_of_vars.remove('date')\n",
    "if 'index_time' in list_of_vars:\n",
    "    list_of_vars.remove('index_time')\n",
    "\n",
    "# create selector\n",
    "selector_reg = Kraken(\n",
    "    estimator=model_reg, \n",
    "    cv=cv_datetime, \n",
    "    metric=MAPE, \n",
    "    meta_info_name='example_regression',\n",
    "    task_type='regression',\n",
    "    greater_is_better=False,\n",
    "    comparison_precision= 2 # lower MAPE is better\n",
    ")\n",
    "\n",
    "# get rank dictionary from variables\n",
    "selector_reg.get_rank_dict(X, y, list_of_vars, group_dt)\n",
    "\n",
    "print(\"Rank dict (regression) top-5:\", dict(list(selector_reg.rank_dict.items())[:5]))\n",
    "\n",
    "# get variables\n",
    "best_vars_reg = selector_reg.get_vars(X, y, rank_dict=selector_reg.rank_dict, group_dt=group_dt, max_feature_search_rounds=10)\n",
    "print(\"Selected vars (regression):\", best_vars_reg)\n",
    "\n",
    "# ==============================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_prod)",
   "language": "python",
   "name": "pytorch_prod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
