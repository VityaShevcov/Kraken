{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification dataset shape: (12000, 10)\n",
      "[get_rank_dict] Starting combined baseline evaluation and SHAP calculation...\n",
      "Fold: 1/3 | Status: Done (0.29s)              | Fold Time:   0.29s | Total Time:    0.30s                              \n",
      "Fold: 2/3 | Status: Done (0.22s)              | Fold Time:   0.22s | Total Time:    0.52s                              \n",
      "Fold: 3/3 | Status: Done (0.18s)              | Fold Time:   0.18s | Total Time:    0.71s                              \n",
      "------------------------------\n",
      "[get_rank_dict] >> FINAL Baseline Performance (All Features)\n",
      "    Mean CV Score: 0.83\n",
      "    Fold Scores: [0.82 0.81 0.84]\n",
      "[get_rank_dict] Completed calculation. Total time: 0.77 seconds.\n",
      "Rank dict (classification) top-5: {'var_2': 1, 'var_3': 2, 'var_1': 3, 'var_7': 4, 'var_5': 5}\n",
      "[get_vars] Evaluating initial feature set (if any)...\n",
      "[get_vars] Starting feature selection procedure...\n",
      "[get_vars] Starting from scratch (will check top 10 features first).\n",
      "\n",
      "--- Starting Step: Selecting feature #1 (Checking top 9) ---\n",
      "    CV Before Step: Inf | Target Summa Threshold to Add: 1\n",
      "Step 1 | Checks: 7/10 | Checking [9/9]: var_4                | Best Add (this step): var_3                (Summa: 3, CV: 0.76))\n",
      "--- Step finished in 4.45 seconds ---\n",
      "[+] Feature Added: 'var_3'\n",
      "    New Best Mean CV: 0.76 (Achieved Summa: 3)\n",
      "    Selected Features (1): ['var_3']\n",
      "    Meta info saved to df_meta_info_example_classification.csv\n",
      "\n",
      "--- Starting Step: Selecting feature #2 (Checking 8) ---\n",
      "    CV Before Step: 0.76 | Target Summa Threshold to Add: 1\n",
      "Step 2 | Checks: 7/10 | Checking [8/8]: var_4                | Best Add (this step): var_2                (Summa: 3, CV: 0.79))\n",
      "--- Step finished in 3.58 seconds ---\n",
      "[+] Feature Added: 'var_2'\n",
      "    New Best Mean CV: 0.79 (Achieved Summa: 3)\n",
      "    Selected Features (2): ['var_3', 'var_2']\n",
      "    Meta info saved to df_meta_info_example_classification.csv\n",
      "\n",
      "--- Starting Step: Selecting feature #3 (Checking 7) ---\n",
      "    CV Before Step: 0.79 | Target Summa Threshold to Add: 1\n",
      "Step 3 | Checks: 6/10 | Checking [7/7]: var_4                | Best Add (this step): var_1                (Summa: 3, CV: 0.83))\n",
      "--- Step finished in 3.49 seconds ---\n",
      "[+] Feature Added: 'var_1'\n",
      "    New Best Mean CV: 0.83 (Achieved Summa: 3)\n",
      "    Selected Features (3): ['var_3', 'var_2', 'var_1']\n",
      "    Meta info saved to df_meta_info_example_classification.csv\n",
      "\n",
      "--- Starting Step: Selecting feature #4 (Checking 6) ---\n",
      "    CV Before Step: 0.83 | Target Summa Threshold to Add: 1\n",
      "Step 4 | Checks: 6/10 | Checking [6/6]: var_4                | Best Add (this step): None                 (Summa: N/A, CV: N/A)\n",
      "--- Step finished in 2.79 seconds ---\n",
      "[-] No feature found that improves the score in this step. Stopping.\n",
      "------------------------------\n",
      "[get_vars] Final feature set:\n",
      "  Features (3): ['var_3', 'var_2', 'var_1']\n",
      "  Best Mean CV achieved: 0.83\n",
      "  Baseline Mean CV (All Features): 0.83\n",
      "[get_vars] Completed in 14.53 seconds.\n",
      "Selected vars (classification): ['var_3', 'var_2', 'var_1']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='shap')\n",
    "\n",
    "# seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# import classes\n",
    "from Tools import DateTimeSeriesSplit, Kraken\n",
    "\n",
    "# model and metric for classification\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# example 2: classification\n",
    "c_clf = 4000\n",
    "\n",
    "# create dataset parts\n",
    "Xc1 = pd.DataFrame()\n",
    "\n",
    "# var_1, var_2, var_3 - features that affect target\n",
    "Xc1['var_1'] = np.random.rand(c_clf)\n",
    "Xc1['var_2'] = np.random.rand(c_clf)\n",
    "Xc1['var_3'] = np.random.rand(c_clf)\n",
    "\n",
    "# var_4..var_9 - noise features\n",
    "for col_i in range(4, 10):\n",
    "    Xc1[f'var_{col_i}'] = np.random.rand(c_clf)\n",
    "\n",
    "# date\n",
    "Xc1['date'] = pd.date_range(start='2005-01-01', periods=c_clf, freq='D')\n",
    "\n",
    "# target\n",
    "y_c1_float = 4 * Xc1['var_1'] + 5 * Xc1['var_2'] + (2*Xc1['var_3'])**2 + 1.0 * np.random.rand(c_clf)\n",
    "y_c1 = (y_c1_float > 6.0).astype(int)\n",
    "\n",
    "Xc2 = Xc1.copy()\n",
    "y_c2 = ((2 * Xc2['var_1'] + 2 * Xc2['var_2'] +  (2*Xc2['var_3'])**1.9) + 1.0*np.random.rand(c_clf) > 6.0).astype(int)\n",
    "Xc3 = Xc1.copy()\n",
    "y_c3 = ((3 * Xc3['var_1'] + 3 * Xc3['var_2'] +  (2*Xc3['var_3'])**1.5)  + 1.0*np.random.rand(c_clf) > 6.0).astype(int)\n",
    "Xc = pd.concat([Xc1, Xc2, Xc3], axis=0)\n",
    "y_c = pd.concat([y_c1, y_c2, y_c3], axis=0).reset_index(drop=True)\n",
    "print(\"Classification dataset shape:\", Xc.shape)\n",
    "\n",
    "cv_datetime_clf = DateTimeSeriesSplit(window=1500, n_splits=3, test_size=300, margin=0)\n",
    "group_dt_clf = Xc['date']\n",
    "\n",
    "# get feature list\n",
    "vars_for_clf = [col for col in Xc.columns if col not in ['date', 'index_time']]\n",
    "model_clf = LGBMClassifier(\n",
    "    max_depth=3, \n",
    "    objective='binary', \n",
    "    verbosity=-1,\n",
    "    random_state=42  # добавляем random_state для воспроизводимости\n",
    ")\n",
    "\n",
    "# metric - accuracy (higher is better)\n",
    "def my_accuracy(y_true, y_pred_prob):\n",
    "    y_bin = (y_pred_prob > 0.5).astype(int)\n",
    "    return accuracy_score(y_true, y_bin)\n",
    "\n",
    "selector_clf = Kraken(\n",
    "    estimator=model_clf,\n",
    "    cv=cv_datetime_clf,\n",
    "    metric=my_accuracy,\n",
    "    meta_info_name='example_classification',\n",
    "    task_type='classification',\n",
    "    greater_is_better=True,\n",
    "    which_class_for_shap=1,\n",
    "    comparison_precision=2\n",
    ")\n",
    "\n",
    "# calculate SHAP importance\n",
    "selector_clf.get_rank_dict(Xc, y_c, vars_for_clf, group_dt_clf)\n",
    "print(\"Rank dict (classification) top-5:\", dict(list(selector_clf.rank_dict.items())[:5]))\n",
    "\n",
    "# greedy feature selection\n",
    "best_vars_clf = selector_clf.get_vars(\n",
    "    X=Xc, \n",
    "    y=y_c, \n",
    "    rank_dict=selector_clf.rank_dict,\n",
    "    group_dt=group_dt_clf,\n",
    "    max_feature_search_rounds=10\n",
    ")\n",
    "print(\"Selected vars (classification):\", best_vars_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_prod)",
   "language": "python",
   "name": "pytorch_prod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
